{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80374292",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T07:00:29.577582Z",
     "iopub.status.busy": "2025-05-03T07:00:29.577381Z",
     "iopub.status.idle": "2025-05-03T07:00:34.968137Z",
     "shell.execute_reply": "2025-05-03T07:00:34.967480Z"
    },
    "papermill": {
     "duration": 5.395538,
     "end_time": "2025-05-03T07:00:34.969529",
     "exception": false,
     "start_time": "2025-05-03T07:00:29.573991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "670cad7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T07:00:34.975717Z",
     "iopub.status.busy": "2025-05-03T07:00:34.975420Z",
     "iopub.status.idle": "2025-05-03T07:00:36.403644Z",
     "shell.execute_reply": "2025-05-03T07:00:36.402827Z"
    },
    "papermill": {
     "duration": 1.432459,
     "end_time": "2025-05-03T07:00:36.404805",
     "exception": false,
     "start_time": "2025-05-03T07:00:34.972346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scanning label files: 100%|██████████| 10/10 [00:01<00:00,  7.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global label_min=1500.00 | label_max=4500.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_inputs = [\n",
    "    f\n",
    "    for f in\n",
    "    Path('/kaggle/input/waveform-inversion/train_samples').rglob('*.npy')\n",
    "    if ('seis' in f.stem) or ('data' in f.stem)\n",
    "]\n",
    "\n",
    "def inputs_files_to_output_files(input_files):\n",
    "    return [\n",
    "        Path(str(f).replace('seis', 'vel').replace('data', 'model'))\n",
    "        for f in input_files\n",
    "    ]\n",
    "\n",
    "all_outputs = inputs_files_to_output_files(all_inputs)\n",
    "\n",
    "assert all(f.exists() for f in all_outputs)\n",
    "\n",
    "train_inputs = [all_inputs[i] for i in range(0, len(all_inputs), 2)] # Sample every two\n",
    "valid_inputs = [f for f in all_inputs if not f in train_inputs]\n",
    "\n",
    "train_outputs = inputs_files_to_output_files(train_inputs)\n",
    "valid_outputs = inputs_files_to_output_files(valid_inputs)\n",
    "\n",
    "def get_global_min_max(label_files):\n",
    "    mins, maxs = [], []\n",
    "    for f in tqdm(label_files, desc=\"scanning label files\"):\n",
    "        arr = np.load(f, mmap_mode=\"r\")\n",
    "        mins.append(arr.min())\n",
    "        maxs.append(arr.max())\n",
    "    return float(np.min(mins)), float(np.max(maxs))\n",
    "\n",
    "label_min, label_max = get_global_min_max(train_outputs)\n",
    "print(f\"Global label_min={label_min:.2f} | label_max={label_max:.2f}\")\n",
    "\n",
    "class SeismicDataset(Dataset):\n",
    "    def __init__(self, inputs_files, output_files, n_examples_per_file=500,label_min=None, label_max=None):\n",
    "        assert len(inputs_files) == len(output_files)\n",
    "        self.inputs_files = inputs_files\n",
    "        self.output_files = output_files\n",
    "        self.n_examples_per_file = n_examples_per_file\n",
    "        self.label_min = label_min\n",
    "        self.label_scale = label_max - label_min\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs_files) * self.n_examples_per_file\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Calculate file offset and sample offset within file\n",
    "        file_idx = idx // self.n_examples_per_file\n",
    "        sample_idx = idx % self.n_examples_per_file\n",
    "\n",
    "        X = np.load(self.inputs_files[file_idx], mmap_mode='r')\n",
    "        y = np.load(self.output_files[file_idx], mmap_mode='r')\n",
    "\n",
    "        # map label to [-1,1] \n",
    "        y = 2.0 * (y - self.label_min) / self.label_scale - 1.0\n",
    "\n",
    "        try:\n",
    "            return X[sample_idx].copy(), y[sample_idx].copy()\n",
    "        finally:\n",
    "            del X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5aa7c83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T07:00:36.411816Z",
     "iopub.status.busy": "2025-05-03T07:00:36.411201Z",
     "iopub.status.idle": "2025-05-03T07:00:36.415701Z",
     "shell.execute_reply": "2025-05-03T07:00:36.414990Z"
    },
    "papermill": {
     "duration": 0.008842,
     "end_time": "2025-05-03T07:00:36.416700",
     "exception": false,
     "start_time": "2025-05-03T07:00:36.407858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dstrain = SeismicDataset(train_inputs, train_outputs,label_min=label_min, label_max=label_max)\n",
    "dsvalid = SeismicDataset(valid_inputs, valid_outputs,label_min=label_min, label_max=label_max)\n",
    "\n",
    "train_loader = DataLoader(dstrain, batch_size=8, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(dsvalid, batch_size=8, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7787d5da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T07:00:36.422863Z",
     "iopub.status.busy": "2025-05-03T07:00:36.422617Z",
     "iopub.status.idle": "2025-05-03T07:00:37.952000Z",
     "shell.execute_reply": "2025-05-03T07:00:37.951177Z"
    },
    "papermill": {
     "duration": 1.533907,
     "end_time": "2025-05-03T07:00:37.953353",
     "exception": false,
     "start_time": "2025-05-03T07:00:36.419446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([8, 5, 1000, 70])\n",
      "Batch target shape: torch.Size([8, 1, 70, 70])\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in train_loader:\n",
    "    print(\"Batch input shape:\", X_batch.shape)\n",
    "    print(\"Batch target shape:\", y_batch.shape)\n",
    "    break  # just check the first batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78fb7ae2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T07:00:37.960203Z",
     "iopub.status.busy": "2025-05-03T07:00:37.959970Z",
     "iopub.status.idle": "2025-05-03T07:00:37.966934Z",
     "shell.execute_reply": "2025-05-03T07:00:37.966455Z"
    },
    "papermill": {
     "duration": 0.011599,
     "end_time": "2025-05-03T07:00:37.968015",
     "exception": false,
     "start_time": "2025-05-03T07:00:37.956416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"Simple 2-layer MLP with GELU and dropout\"\"\"\n",
    "    def __init__(self, dim, hidden_dim, drop=0.):\n",
    "        super().__init__()\n",
    "        self.fc1   = nn.Linear(dim, hidden_dim)\n",
    "        self.act   = nn.GELU()\n",
    "        self.fc2   = nn.Linear(hidden_dim, dim)\n",
    "        self.drop  = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.drop(self.act(self.fc1(x)))\n",
    "        x = self.drop(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    ViT-style encoder block\n",
    "    LayerNorm  →  Multi-Head Self-Attention  →  residual\n",
    "    LayerNorm  →  MLP                        →  residual\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4., drop=0., attn_drop=0.):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.attn  = nn.MultiheadAttention(\n",
    "            embed_dim=dim, num_heads=num_heads,\n",
    "            dropout=attn_drop, batch_first=True)\n",
    "        self.drop1 = nn.Dropout(drop)\n",
    "\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp   = MLP(dim, hidden_dim, drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (B, N, D)\n",
    "        # --- self-attention ---\n",
    "        attn_out, _ = self.attn(self.norm1(x), self.norm1(x), self.norm1(x))\n",
    "        x = x + self.drop1(attn_out)\n",
    "\n",
    "        # --- feed-forward ---\n",
    "        x = x + self.mlp(self.norm2(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8351ff79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T07:00:37.975571Z",
     "iopub.status.busy": "2025-05-03T07:00:37.975361Z",
     "iopub.status.idle": "2025-05-03T07:00:37.983491Z",
     "shell.execute_reply": "2025-05-03T07:00:37.982983Z"
    },
    "papermill": {
     "duration": 0.01353,
     "end_time": "2025-05-03T07:00:37.984487",
     "exception": false,
     "start_time": "2025-05-03T07:00:37.970957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SeismicViT(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_ch=5, patch=(25,5), embed_dim=256,\n",
    "                 depth=10, num_heads=8, mlp_ratio=4.,\n",
    "                 out_size=(70,70)):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1) patchify\n",
    "        self.patch_embed = nn.Conv2d(in_ch, embed_dim,\n",
    "                                     kernel_size=patch, stride=patch) # B,embed_dim,40,14\n",
    "        num_patches = (1000 // patch[0]) * (70 // patch[1]) # 40 * 14 = 560\n",
    "        self.pos = nn.Parameter(torch.zeros(1, num_patches, embed_dim)) # (1, 560, 256)\n",
    "\n",
    "        # 2) Transformer encoder\n",
    "        self.blocks = nn.ModuleList([\n",
    "            TransformerBlock(embed_dim, num_heads, mlp_ratio)\n",
    "            for _ in range(depth)\n",
    "        ])\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # 3) linear projector to patch-level velocity\n",
    "        self.head = nn.Linear(embed_dim, patch[0]*patch[1])\n",
    "\n",
    "        # 4) light decoder to 1000×70\n",
    "        self.up = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1, 32, 4, 2, 1),  # 125→250\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose2d(32, 16, 4, 2, 1), # 250→500\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose2d(16,  1, 4, 2, 1), # 500→1000\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(1, 1, kernel_size=3, padding=1)  # 1000×70 → 1000×70\n",
    "        )\n",
    "    def forward(self, x):                        # (B,5,1000,70)\n",
    "        x = self.patch_embed(x).flatten(2).permute(0,2,1)  # -> (B, 256, 560) -> (B, 560, 256)   # (batch, tokens, embed_dim)\n",
    "        x = x + self.pos  #(B, 560, 256) \n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.head(x)                         # (B,N,PatchArea) (B, 560, 125)\n",
    "        x = x.view(-1, 1, 1000, 70)             # (B,1,1000,70)\n",
    "        x = F.avg_pool2d(x, kernel_size=(8,1))   # 1000→125   keep 70 (B, 1, 125, 70)\n",
    "        assert x.shape[1:] == (1, 125, 70), f\"Expected (B,1,125,70) but got {x.shape}\"\n",
    "        x = self.up(x)                        # (B,1,1000,70)\n",
    "        return torch.tanh(F.interpolate(x, size=(70,70), mode='bilinear', align_corners=False)) # interpolate to (70*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b848d6e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T07:00:37.990740Z",
     "iopub.status.busy": "2025-05-03T07:00:37.990539Z",
     "iopub.status.idle": "2025-05-03T08:03:50.334806Z",
     "shell.execute_reply": "2025-05-03T08:03:50.333670Z"
    },
    "papermill": {
     "duration": 3792.826879,
     "end_time": "2025-05-03T08:03:50.814069",
     "exception": false,
     "start_time": "2025-05-03T07:00:37.987190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 1: 100%|██████████| 625/625 [02:11<00:00,  4.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | train 0.2494 | val 0.2065\n",
      "✅  New best model saved (val loss 0.2065)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 2: 100%|██████████| 625/625 [02:17<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | train 0.2073 | val 0.2070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 3: 100%|██████████| 625/625 [02:17<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | train 0.1981 | val 0.1988\n",
      "✅  New best model saved (val loss 0.1988)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 4: 100%|██████████| 625/625 [02:17<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | train 0.1884 | val 0.2264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 5: 100%|██████████| 625/625 [02:17<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | train 0.1789 | val 0.1732\n",
      "✅  New best model saved (val loss 0.1732)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 6: 100%|██████████| 625/625 [02:17<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | train 0.1655 | val 0.1659\n",
      "✅  New best model saved (val loss 0.1659)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 7: 100%|██████████| 625/625 [02:18<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | train 0.1579 | val 0.1670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 8: 100%|██████████| 625/625 [02:17<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | train 0.1526 | val 0.1582\n",
      "✅  New best model saved (val loss 0.1582)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 9: 100%|██████████| 625/625 [02:17<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | train 0.1474 | val 0.1528\n",
      "✅  New best model saved (val loss 0.1528)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 10: 100%|██████████| 625/625 [02:18<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | train 0.1462 | val 0.1455\n",
      "✅  New best model saved (val loss 0.1455)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 11: 100%|██████████| 625/625 [02:18<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | train 0.1405 | val 0.1399\n",
      "✅  New best model saved (val loss 0.1399)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 12: 100%|██████████| 625/625 [02:18<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | train 0.1388 | val 0.1425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 13: 100%|██████████| 625/625 [02:18<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | train 0.1313 | val 0.1330\n",
      "✅  New best model saved (val loss 0.1330)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 14: 100%|██████████| 625/625 [02:18<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | train 0.1255 | val 0.1269\n",
      "✅  New best model saved (val loss 0.1269)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 15: 100%|██████████| 625/625 [02:18<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | train 0.1228 | val 0.1239\n",
      "✅  New best model saved (val loss 0.1239)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 16: 100%|██████████| 625/625 [02:18<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | train 0.1197 | val 0.1184\n",
      "✅  New best model saved (val loss 0.1184)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 17: 100%|██████████| 625/625 [02:18<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | train 0.1204 | val 0.1288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 18: 100%|██████████| 625/625 [02:18<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | train 0.1191 | val 0.1163\n",
      "✅  New best model saved (val loss 0.1163)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 19: 100%|██████████| 625/625 [02:18<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | train 0.1094 | val 0.1065\n",
      "✅  New best model saved (val loss 0.1065)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 20: 100%|██████████| 625/625 [02:18<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | train 0.1084 | val 0.1121\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "model = SeismicViT().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # ── 1. TRAIN ───────────────────────────────────────────────────────\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for xb, yb in tqdm(train_loader, desc=f\"[Train] Epoch {epoch+1}\"):\n",
    "        xb, yb = xb.to(device), yb.to(device).squeeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb).squeeze(1)\n",
    "        loss  = loss_fn(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # ── 2. VALIDATE ────────────────────────────────────────────────────\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device).squeeze(1)\n",
    "            preds  = model(xb).squeeze(1)\n",
    "            val_loss += loss_fn(preds, yb).item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    print(f\"Epoch {epoch+1} | train {train_loss:.4f} | val {val_loss:.4f}\")\n",
    "\n",
    "    # ── 3. CHECKPOINT ON VAL LOSS ─────────────────────────────────────\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), '/kaggle/working/best_model.pth')\n",
    "        print(f\"✅  New best model saved (val loss {best_val_loss:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72c2bc38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T08:03:51.838656Z",
     "iopub.status.busy": "2025-05-03T08:03:51.838028Z",
     "iopub.status.idle": "2025-05-03T08:03:52.739094Z",
     "shell.execute_reply": "2025-05-03T08:03:52.738312Z"
    },
    "papermill": {
     "duration": 1.372035,
     "end_time": "2025-05-03T08:03:52.740197",
     "exception": false,
     "start_time": "2025-05-03T08:03:51.368162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 248 ms, sys: 56.4 ms, total: 305 ms\n",
      "Wall time: 894 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "65818"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "test_files = list(Path('/kaggle/input/waveform-inversion/test').glob('*.npy'))\n",
    "len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b6d62e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T08:03:53.744396Z",
     "iopub.status.busy": "2025-05-03T08:03:53.744142Z",
     "iopub.status.idle": "2025-05-03T08:03:53.749492Z",
     "shell.execute_reply": "2025-05-03T08:03:53.748938Z"
    },
    "papermill": {
     "duration": 0.480413,
     "end_time": "2025-05-03T08:03:53.750582",
     "exception": false,
     "start_time": "2025-05-03T08:03:53.270169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_cols = [f'x_{i}' for i in range(1, 70, 2)]\n",
    "fieldnames = ['oid_ypos'] + x_cols\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, test_files):\n",
    "        self.test_files = test_files\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.test_files)\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        test_file = self.test_files[i]\n",
    "\n",
    "        return np.load(test_file), test_file.stem\n",
    "\n",
    "ds = TestDataset(test_files)\n",
    "dl = DataLoader(ds, batch_size=8, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6c65c90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T08:03:54.748263Z",
     "iopub.status.busy": "2025-05-03T08:03:54.747979Z",
     "iopub.status.idle": "2025-05-03T08:16:33.360150Z",
     "shell.execute_reply": "2025-05-03T08:16:33.358966Z"
    },
    "papermill": {
     "duration": 759.092659,
     "end_time": "2025-05-03T08:16:33.370536",
     "exception": false,
     "start_time": "2025-05-03T08:03:54.277877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: 100%|██████████| 8228/8228 [12:38<00:00, 10.85it/s]\n"
     ]
    }
   ],
   "source": [
    "PATH = \"/kaggle/working/best_model.pth\" \n",
    "model.eval()\n",
    "model.load_state_dict(torch.load(PATH, weights_only=True))\n",
    "\n",
    "with open('submission.csv', 'wt', newline='') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for inputs, oids_test in tqdm(dl, desc='test'):\n",
    "        inputs = inputs.to(device)\n",
    "        with torch.inference_mode():\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "        preds_norm = outputs[:, 0]\n",
    "        preds_true = 0.5 * (preds_norm + 1.0) * (label_max - label_min) + label_min\n",
    "        y_preds    = preds_true.cpu().numpy()\n",
    "        \n",
    "        for y_pred, oid_test in zip(y_preds, oids_test):\n",
    "            for y_pos in range(70):\n",
    "                row = dict(\n",
    "                    zip(\n",
    "                        x_cols,\n",
    "                        [y_pred[y_pos, x_pos] for x_pos in range(1, 70, 2)]\n",
    "                    )\n",
    "                )\n",
    "                row['oid_ypos'] = f\"{oid_test}_y_{y_pos}\"\n",
    "            \n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095e1e2a",
   "metadata": {
    "papermill": {
     "duration": 0.63117,
     "end_time": "2025-05-03T08:16:34.802288",
     "exception": false,
     "start_time": "2025-05-03T08:16:34.171118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11756775,
     "sourceId": 39763,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4573.103377,
   "end_time": "2025-05-03T08:16:38.614915",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-03T07:00:25.511538",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
